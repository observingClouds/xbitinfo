{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f40619",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2d4f5-c444-404a-8444-3648cb0a94bf",
   "metadata": {},
   "source": [
    "Geospatial data can vary in its information density from one part of the world to another. A dataset containing streets will be very dense in cities but contains little information in remote places like the Alps or even the ocean. The same is also true for datasets about the ocean or the atmosphere.\n",
    "\n",
    "By default the number of bits that need to be kept (`keepbits`) to preserve the requested amount of information is determined based on the entire dataset. This approach doesn't always result in the best compression rates as it preserves too many keepbits in regions with anomalously low information density. The following steps show how the `keepbits` can be retrieved and applied on subsets. In this case, subsets are defined as dataset chunks.\n",
    "\n",
    "This work is a result of the ECMWF Code4Earth 2023. Please have a look at the [presentation of this project](https://youtu.be/IOi4XvECpsQ?si=hwZkppNRa-J2XVZ9) for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515b4bd-a302-45a9-8464-56b67a73a46c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9149e-fc6d-4048-8e45-a29966e5c6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr\n",
    "import xbitinfo as xb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e0873-0a27-4757-947a-4a559a102288",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320224c9-06e2-428a-8614-8ed0d15eee82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "ds = xr.tutorial.load_dataset(\"air_temperature\")\n",
    "\n",
    "# Defining chunks that will be used for the reading/bitrounding/writing\n",
    "chunks = {\n",
    "    \"lat\": 5,\n",
    "    \"lon\": 10,\n",
    "}\n",
    "\n",
    "# Apply chunking\n",
    "ds = ds.chunk(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3120040-79f1-4a7f-a61f-afec9fb3ca5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b95de-f8e5-45c3-be3b-0555a67efb77",
   "metadata": {},
   "source": [
    "## Zarr chunking and compressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91343d2a-63ec-4d61-a369-cc99139297e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bitrounding(chunk, var=\"lat\"):\n",
    "    \"\"\"\n",
    "    Just a function that handles all the xbitinfo calls\n",
    "    \"\"\"\n",
    "    bitinfo = xb.get_bitinformation(chunk, dim=var, implementation=\"python\")\n",
    "    keepbits = xb.get_keepbits(bitinfo, 0.99)\n",
    "    bitround = xb.xr_bitround(chunk, keepbits)\n",
    "    return bitround, keepbits\n",
    "\n",
    "\n",
    "def slices_from_chunks(chunks):\n",
    "    \"\"\"Translate chunks tuple to a set of slices in product order\n",
    "\n",
    "    >>> slices_from_chunks(((2, 2), (3, 3, 3)))  # doctest: +NORMALIZE_WHITESPACE\n",
    "     [(slice(0, 2, None), slice(0, 3, None)),\n",
    "      (slice(0, 2, None), slice(3, 6, None)),\n",
    "      (slice(0, 2, None), slice(6, 9, None)),\n",
    "      (slice(2, 4, None), slice(0, 3, None)),\n",
    "      (slice(2, 4, None), slice(3, 6, None)),\n",
    "      (slice(2, 4, None), slice(6, 9, None))]\n",
    "    \"\"\"\n",
    "    cumdims = []\n",
    "    for bds in chunks:\n",
    "        out = np.empty(len(bds) + 1, dtype=int)\n",
    "        out[0] = 0\n",
    "        np.cumsum(bds, out=out[1:])\n",
    "        cumdims.append(out)\n",
    "    slices = [\n",
    "        [slice(s, s + dim) for s, dim in zip(starts, shapes)]\n",
    "        for starts, shapes in zip(cumdims, chunks)\n",
    "    ]\n",
    "    return list(product(*slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221b47f-b8f4-4ebf-bc2b-cb61d12989be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save dataset as compressed zarr after compressing individual chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ed18f-4dc8-4f5c-88ed-ae5ad41d1647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fn = \"air_bitrounded_by_chunks.zarr\"  # Output filename\n",
    "ds.to_compressed_zarr(fn, compute=False, mode=\"w\")  # Creates empty file structure\n",
    "\n",
    "dims = ds.air.dims\n",
    "len_dims = len(dims)\n",
    "\n",
    "slices = slices_from_chunks(ds.air.chunks)\n",
    "\n",
    "# Loop over each chunk\n",
    "keepbits = []\n",
    "for b, block in enumerate(ds.air.data.to_delayed().ravel()):\n",
    "    # Conversion of dask.delayed array to Dataset (as xbitinfo wants type xr.Dataset)\n",
    "    ds_block = xr.Dataset({\"air\": (dims, block.compute())})\n",
    "\n",
    "    # Apply bitrounding\n",
    "    rounded_ds, keepbit = bitrounding(ds_block)\n",
    "    keepbits.append(keepbit)\n",
    "\n",
    "    # Write individual chunk to disk\n",
    "    rounded_ds.to_zarr(fn, region={dims[d]: s for (d, s) in enumerate(slices[b])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d628121-d5ec-4544-a47f-f47c86524b09",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8835a3c-8af0-4423-baf4-84aa9a386f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patheffects as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5f657-cddd-4476-82a3-c3c2c1a6e7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a figure and axis and plot the air temperature\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rounded_ds = xr.open_zarr(fn).isel(time=0)\n",
    "rounded_ds[\"air\"].plot(ax=ax, cmap=\"RdBu_r\")\n",
    "\n",
    "slices = slices_from_chunks(rounded_ds.air.chunks)\n",
    "\n",
    "for i in range(len(slices)):\n",
    "    # Get chunk limits\n",
    "    dss = rounded_ds.isel(lat=slices[i][0], lon=slices[i][1])\n",
    "    lats = dss.lat\n",
    "    longs = dss.lon\n",
    "\n",
    "    x = float(min(longs[0], longs[-1]))\n",
    "    y = float(min(lats[0], lats[-1]))\n",
    "    w = float(abs(longs[0] - longs[-1]))\n",
    "    h = float(abs(lats[0] - lats[-1]))\n",
    "\n",
    "    # Draw rectangle\n",
    "    rect = mpl.patches.Rectangle(\n",
    "        (x, y),\n",
    "        width=w,\n",
    "        height=h,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"#E5E4E2\",\n",
    "        path_effects=[pe.withStroke(linewidth=3, foreground=\"gray\")],\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Annotate number of keepbits\n",
    "    rx, ry = rect.get_xy()\n",
    "    cx = rx + rect.get_width() / 2.0\n",
    "    cy = ry + rect.get_height() / 2.0\n",
    "    ax.annotate(\n",
    "        f\"{int(keepbits[i].air):2}\",\n",
    "        (cx, cy),\n",
    "        color=\"k\",\n",
    "        weight=\"normal\",\n",
    "        fontsize=14,\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        path_effects=[pe.withStroke(linewidth=2, foreground=\"w\")],\n",
    "    )\n",
    "\n",
    "fig.text(0.39, 0.94, f\"Keepbits \", weight=\"bold\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8fe5a-2e4e-4dfd-8026-0991e9988668",
   "metadata": {},
   "source": [
    "## Reference compression\n",
    "For comparision with other compression approaches the dataset is also saved as:\n",
    "- uncompressed netCDF\n",
    "- lossless compressed zarr\n",
    "- lossy compressed zarr while preserving 99% of bitinformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77919ff",
   "metadata": {},
   "source": [
    "### Saving to uncompressed `NetCDF` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011a900-5da2-40be-a292-d81a0cafcd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the dataset as NetCDF file\n",
    "ds.to_netcdf(\"0.air_original.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc93427",
   "metadata": {},
   "source": [
    "### Save dataset as compressed zarr (without bitrounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19032fcd-93bc-48b8-ba1f-beba9673491b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = \"air_compressed.zarr\"  # Output filename\n",
    "ds.to_compressed_zarr(fn, mode=\"w\")  # Creates empty file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f759c",
   "metadata": {},
   "source": [
    "### Save dataset as compressed zarr after applying bitrounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb4cd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fn = \"air_bitrounded.zarr\"  # Output filename\n",
    "rounded_ds, keepbits = bitrounding(ds)\n",
    "rounded_ds.to_compressed_zarr(fn, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b60c66-252d-48a6-af93-a00c9ca8f0ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28089ea-22f9-45c6-abc9-b65bd946ac66",
   "metadata": {},
   "source": [
    "Below are the file sizes resulting from the various compression techniques outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998581b5-6ad9-4f6f-9c61-d0bf1486ec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!du -hs *.nc *.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6975d-6909-4e2c-9395-0a64d39ed44f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed34f3f-2bee-45d3-9bdf-1237b77cf1b8",
   "metadata": {},
   "source": [
    "In this experiment, the sizes are minimized when applying bitrounding and compression to the dataset chunks. \n",
    "\n",
    "However, it's important to note that this outcome may not be universally applicable, check this for your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
